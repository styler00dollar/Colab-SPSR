{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-SPSR.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLGW-5VaCaeo",
        "colab_type": "text"
      },
      "source": [
        "# Colab-SPSR\n",
        "\n",
        "This colab uses [Maclory/SPSR](https://github.com/Maclory/SPSR) or rather [BlueAmulet/SPSR](https://github.com/BlueAmulet/SPSR).\n",
        "\n",
        "My fork is located in [styler00dollar/Colab-SPSR](https://github.com/styler00dollar/Colab-SPSR)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcVm337ZF1s1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtA0lHcb-iKq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install and download models\n",
        "!git clone https://github.com/BlueAmulet/SPSR\n",
        "!pip install numpy opencv-python lmdb pyyaml\n",
        "!pip install tb-nightly future\n",
        "!pip install gdown\n",
        "%cd /content/SPSR/experiments/pretrained_models\n",
        "!gdown --id 1JxFvPG4YBcCkOBOaUEDTDrRNheUkojrK\n",
        "!gdown --id 1uqt5M8vFYyW6UCCR5zpTg-kHrutDPN_5\n",
        "!gdown --id 1fgMAaQzPk_SxaR6FnvKrzjE2D0b8Gosx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ungsMLSsCphf",
        "colab_type": "text"
      },
      "source": [
        "Place pictures in ```/content/input_data``` and the result will be in ```/content/result```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvmKxOhC4Y9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Creating empty folders for input and output\n",
        "!mkdir /content/input_data\n",
        "!mkdir /content/result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqTAWoolAhfQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Modify test config file\n",
        "%%writefile /content/SPSR/code/options/test/test_spsr.yml\n",
        "model: 'spsr'\n",
        "scale: 4\n",
        "gpu_ids: [0]\n",
        "\n",
        "datasets:\n",
        "  test_1:\n",
        "    name: 'set5'\n",
        "    mode: 'LR'\n",
        "    # dataroot_HR: '/mnt/4/jzy/dataset/SR_dataset/test_datasets/Set5/Set5_HR' # needed in 'LRHR' mode\n",
        "    dataroot_LR: '/content/input_data'\n",
        "path:\n",
        "  root: '/' # change to your own root path\n",
        "  #resume_state: '../experiments/002_RRDB_ESRGAN_x4_DIV2K/training_state/65000.state'\n",
        "  pretrain_model_G: '/content/SPSR/experiments/pretrained_models/spsr.pth'\n",
        "\n",
        "network_G:\n",
        "  which_model_G: 'spsr_net'\n",
        "  norm_type: null\n",
        "  mode: 'CNA'\n",
        "  nf: 64\n",
        "  nb: 23\n",
        "  in_nc: 3\n",
        "  out_nc: 3\n",
        "\n",
        "  gc: 32\n",
        "  group: 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khjc4-CPB16a",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Modify output path in options.py\n",
        "%%writefile /content/SPSR/code/options/options.py\n",
        "import os\n",
        "import os.path as osp\n",
        "import logging\n",
        "\n",
        "\n",
        "def parse(opt_path, is_train=True):\n",
        "    extension = osp.splitext(opt_path)[1].lower()\n",
        "    if extension == '.json':\n",
        "        import json\n",
        "        # remove comments starting with '//'\n",
        "        json_str = ''\n",
        "        with open(opt_path, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.split('//')[0] + '\\n'\n",
        "                json_str += line\n",
        "        opt = json.loads(json_str, object_pairs_hook=OrderedDict)\n",
        "    elif extension == '.cson':\n",
        "        import cson\n",
        "        with open(opt_path, 'r') as f:\n",
        "            opt = cson.load(f)\n",
        "    elif extension == '.yml' or extension == '.yaml':\n",
        "        import yaml\n",
        "        with open(opt_path, 'r') as f:\n",
        "            opt = yaml.safe_load(f)\n",
        "    else:\n",
        "        raise ValueError('Unknown file extension: {}'.format(extension))\n",
        "\n",
        "    opt['is_train'] = is_train\n",
        "    scale = opt['scale']\n",
        "\n",
        "    # datasets\n",
        "    for phase, dataset in opt['datasets'].items():\n",
        "        phase = phase.split('_')[0]\n",
        "        dataset['phase'] = phase\n",
        "        dataset['scale'] = scale\n",
        "        is_lmdb = False\n",
        "        if 'dataroot_HR' in dataset and dataset['dataroot_HR'] is not None:\n",
        "            dataset['dataroot_HR'] = os.path.expanduser(dataset['dataroot_HR'])\n",
        "            if dataset['dataroot_HR'].endswith('lmdb'):\n",
        "                is_lmdb = True\n",
        "        if 'dataroot_HR_bg' in dataset and dataset['dataroot_HR_bg'] is not None:\n",
        "            dataset['dataroot_HR_bg'] = os.path.expanduser(dataset['dataroot_HR_bg'])\n",
        "        if 'dataroot_LR' in dataset and dataset['dataroot_LR'] is not None:\n",
        "            dataset['dataroot_LR'] = os.path.expanduser(dataset['dataroot_LR'])\n",
        "            if dataset['dataroot_LR'].endswith('lmdb'):\n",
        "                is_lmdb = True\n",
        "        dataset['data_type'] = 'lmdb' if is_lmdb else 'img'\n",
        "\n",
        "        if phase == 'train' and 'subset_file' in dataset and dataset['subset_file'] is not None:\n",
        "            dataset['subset_file'] = os.path.expanduser(dataset['subset_file'])\n",
        "\n",
        "    # path\n",
        "    for key, path in opt['path'].items():\n",
        "        if path and key in opt['path']:\n",
        "            opt['path'][key] = os.path.expanduser(path)\n",
        "    if is_train:\n",
        "        experiments_root = os.path.join(opt['path']['root'], 'experiments', opt['name'])\n",
        "        opt['path']['experiments_root'] = experiments_root\n",
        "        opt['path']['models'] = os.path.join(experiments_root, 'models')\n",
        "        opt['path']['training_state'] = os.path.join(experiments_root, 'training_state')\n",
        "        opt['path']['log'] = experiments_root\n",
        "        opt['path']['val_images'] = os.path.join(experiments_root, 'val_images')\n",
        "\n",
        "        # change some options for debug mode\n",
        "        if 'debug' in opt['name']:\n",
        "            opt['train']['val_freq'] = 8\n",
        "            opt['logger']['print_freq'] = 2\n",
        "            opt['logger']['save_checkpoint_freq'] = 8\n",
        "            opt['train']['lr_decay_iter'] = 10\n",
        "    else:  # test\n",
        "        results_root = '/content/result'\n",
        "        opt['path']['results_root'] = results_root\n",
        "        opt['path']['log'] = results_root\n",
        "\n",
        "    # network\n",
        "    opt['network_G']['scale'] = scale\n",
        "\n",
        "    # export CUDA_VISIBLE_DEVICES\n",
        "    gpu_list = ','.join(str(x) for x in opt['gpu_ids'])\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n",
        "    print('export CUDA_VISIBLE_DEVICES=' + gpu_list)\n",
        "\n",
        "    return opt\n",
        "\n",
        "\n",
        "class NoneDict(dict):\n",
        "    def __missing__(self, key):\n",
        "        return None\n",
        "\n",
        "\n",
        "# convert to NoneDict, which return None for missing key.\n",
        "def dict_to_nonedict(opt):\n",
        "    if isinstance(opt, dict):\n",
        "        new_opt = dict()\n",
        "        for key, sub_opt in opt.items():\n",
        "            new_opt[key] = dict_to_nonedict(sub_opt)\n",
        "        return NoneDict(**new_opt)\n",
        "    elif isinstance(opt, list):\n",
        "        return [dict_to_nonedict(sub_opt) for sub_opt in opt]\n",
        "    else:\n",
        "        return opt\n",
        "\n",
        "\n",
        "def dict2str(opt, indent_l=1):\n",
        "    '''dict to string for logger'''\n",
        "    msg = ''\n",
        "    for k, v in opt.items():\n",
        "        if isinstance(v, dict):\n",
        "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
        "            msg += dict2str(v, indent_l + 1)\n",
        "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
        "        else:\n",
        "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
        "    return msg\n",
        "\n",
        "\n",
        "def check_resume(opt):\n",
        "    '''Check resume states and pretrain_model paths'''\n",
        "    logger = logging.getLogger('base')\n",
        "    if opt['path']['resume_state']:\n",
        "        if opt['path']['pretrain_model_G'] or opt['path']['pretrain_model_D']:\n",
        "            logger.warning('pretrain_model path will be ignored when resuming training.')\n",
        "\n",
        "        state_idx = osp.basename(opt['path']['resume_state']).split('.')[0]\n",
        "        opt['path']['pretrain_model_G'] = osp.join(opt['path']['models'],\n",
        "                                                   '{}_G.pth'.format(state_idx))\n",
        "        logger.info('Set [pretrain_model_G] to ' + opt['path']['pretrain_model_G'])\n",
        "        if 'gan' in opt['model']:\n",
        "            opt['path']['pretrain_model_D'] = osp.join(opt['path']['models'],\n",
        "                                                       '{}_D.pth'.format(state_idx))\n",
        "            logger.info('Set [pretrain_model_D] to ' + opt['path']['pretrain_model_D'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L3ZB--oEsiD",
        "colab_type": "text"
      },
      "source": [
        "Warning: It needs a lot more VRAM compared to ESRGAN. Try a bit smaller files. \n",
        "\n",
        "480x360 out of memory error with 8GB K80."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyJkqcs3-hX8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Running SPSR\n",
        "!python /content/SPSR/code/test.py -opt /content/SPSR/code/options/test/test_spsr.yml"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}